{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import operator\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import keras\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img \n",
    "from keras.models import Sequential \n",
    "from keras import optimizers\n",
    "from keras.preprocessing import image\n",
    "from keras.layers import Dropout, Flatten, Dense \n",
    "from keras import applications \n",
    "from keras.utils.np_utils import to_categorical \n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "import math \n",
    "import datetime\n",
    "import time\n",
    "import queue\n",
    "from multiprocessing import Queue\n",
    "from PIL import Image\n",
    "import xlsxwriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# module level variables\n",
    "MIN_CONTOUR_AREA = 100\n",
    "\n",
    "RESIZED_IMAGE_WIDTH = 20\n",
    "RESIZED_IMAGE_HEIGHT = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Default dimensions we found online\n",
    "img_width, img_height = 224, 224 \n",
    " \n",
    "#Create a bottleneck file\n",
    "top_model_weights_path = 'bottleneck_fc_model.h5'\n",
    "# loading up our datasets\n",
    "train_data_dir = 'data/train'\n",
    "validation_data_dir = 'data/validation'\n",
    "test_data_dir = 'data/test'\n",
    " \n",
    "# number of epochs to train top model \n",
    "epochs = 7 #this has been changed after multiple model run \n",
    "# batch size used by flow_from_directory and predict_generator \n",
    "batch_size = 50 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0912 13:39:56.560084  3364 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0912 13:39:56.930793  3364 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0912 13:39:57.000202  3364 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0912 13:39:57.100350  3364 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0912 13:39:58.498713  3364 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0912 13:39:58.498713  3364 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Loading vgc16 model\n",
    "vgg16 = applications.VGG16(include_top=False, weights='imagenet')\n",
    "datagen = ImageDataGenerator(rescale=1. / 255) \n",
    "#needed to create the bottleneck .npy files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 85552 images belonging to 61 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#training data\n",
    "generator_top = datagen.flow_from_directory( \n",
    "   train_data_dir, \n",
    "   target_size=(img_width, img_height), \n",
    "   batch_size=batch_size, \n",
    "   class_mode='categorical', \n",
    "   shuffle=False) \n",
    " \n",
    "nb_train_samples = len(generator_top.filenames) \n",
    "num_classes = len(generator_top.class_indices) \n",
    " \n",
    "# load the bottleneck features saved earlier \n",
    "train_data = np.load('bottleneck_features_train.npy') \n",
    " \n",
    "# get the class labels for the training data, in the original order \n",
    "train_labels = generator_top.classes \n",
    " \n",
    "# convert the training labels to categorical vectors \n",
    "train_labels = to_categorical(train_labels, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#validation data\\n\",\n",
    "generator_top = datagen.flow_from_directory(\n",
    "             validation_data_dir,  \n",
    "             target_size=(img_width, img_height),  \n",
    "             batch_size=batch_size,  \n",
    "             class_mode=None,  \n",
    "             shuffle=False)  \n",
    "       \n",
    "nb_validation_samples = len(generator_top.filenames)  \n",
    "       \n",
    "validation_data = np.load('bottleneck_features_validation.npy')  \n",
    "       \n",
    "    \n",
    "validation_labels = generator_top.classes  \n",
    "validation_labels = to_categorical(validation_labels, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#testing data\\n\",\n",
    "generator_top = datagen.flow_from_directory(  \n",
    "             test_data_dir,  \n",
    "             target_size=(img_width, img_height),  \n",
    "             batch_size=batch_size,  \n",
    "             class_mode=None,  \n",
    "             shuffle=False)  \n",
    "       \n",
    "nb_test_samples = len(generator_top.filenames)  \n",
    "       \n",
    "test_data = np.load('bottleneck_features_test.npy')  \n",
    "       \n",
    "    \n",
    "test_labels = generator_top.classes \n",
    "test_labels = to_categorical(test_labels, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#This is the best model we found. For additional models, check out I_notebook.ipynb\n",
    "start = datetime.datetime.now()\n",
    "model = Sequential() \n",
    "model.add(Flatten(input_shape=train_data.shape[1:])) \n",
    "model.add(Dense(100, activation=keras.layers.LeakyReLU(alpha=0.3))) \n",
    "model.add(Dropout(0.5)) \n",
    "model.add(Dense(50, activation=keras.layers.LeakyReLU(alpha=0.3))) \n",
    "model.add(Dropout(0.3)) \n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "   optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "   metrics=['acc'])\n",
    "history = model.fit(train_data, train_labels, \n",
    "   epochs=4,\n",
    "   batch_size=batch_size, \n",
    "   validation_data=(validation_data, validation_labels))\n",
    "model.save_weights(top_model_weights_path)\n",
    "(eval_loss, eval_accuracy) = model.evaluate( \n",
    "    validation_data, validation_labels, batch_size=batch_size,     verbose=1)\n",
    "print(\"[INFO] accuracy: {:.2f}%\".format(eval_accuracy * 100)) \n",
    "#print(\"[INFO] Loss: {}\".format(eval_loss)) \n",
    "end= datetime.datetime.now()\n",
    "elapsed= end-start\n",
    "print ('Time: ', elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContourWithData():\n",
    "\n",
    "    # member variables ############################################################################\n",
    "    npaContour = None           # contour\n",
    "    boundingRect = None         # bounding rect for contour\n",
    "    intRectX = 0                # bounding rect top left corner x location\n",
    "    intRectY = 0                # bounding rect top left corner y location\n",
    "    intRectWidth = 0            # bounding rect width\n",
    "    intRectHeight = 0           # bounding rect height\n",
    "    fltArea = 0.0               # area of contour\n",
    "\n",
    "    def calculateRectTopLeftPointAndWidthAndHeight(self):               # calculate bounding rect info\n",
    "        [intX, intY, intWidth, intHeight] = self.boundingRect\n",
    "        self.intRectX = intX\n",
    "        self.intRectY = intY\n",
    "        self.intRectWidth = intWidth\n",
    "        self.intRectHeight = intHeight\n",
    "\n",
    "    def checkIfContourIsValid(self):                            # this is oversimplified, for a production grade program\n",
    "        if self.fltArea < MIN_CONTOUR_AREA: return False        # much better validity checking would be necessary\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import*\n",
    "\n",
    "#Image Resize\n",
    "\n",
    "RPath = r'C:\\Users\\th4pa\\93.jpg'\n",
    "basewidth = 400\n",
    "img = Image.open(RPath)\n",
    "wpercent = (basewidth/float(img.size[0]))\n",
    "hsize = int((float(img.size[1])*float(wpercent)))\n",
    "img = img.resize((basewidth,hsize), Image.ANTIALIAS)\n",
    "img.save(RPath)\n",
    "\n",
    "#Image Segment\n",
    "\n",
    "temp=Image.open(RPath)                      # Take Image\n",
    "temp=temp.convert('1')                        # Convert to black & white\n",
    "A = array(temp)                               # Creates an array, white pixels==True and black pixels==False\n",
    "new_A= empty((A.shape[0],A.shape[1]),None)    # New array with same size as A\n",
    "\n",
    "for i in range(len(A)):\n",
    "    for j in range(len(A[i])):\n",
    "        if A[i][j]==True:\n",
    "            new_A[i][j]=255                   # Set Pixel Values \n",
    "        else:\n",
    "            new_A[i][j]=0                     # Set Pixel Values\n",
    "            \n",
    "\n",
    "workbook = xlsxwriter.Workbook('test.xlsx')   # Create File\n",
    "worksheet = workbook.add_worksheet()\n",
    "for i in range(len(A)):\n",
    "    for j in range(len(A[i])):\n",
    "        worksheet.write(i, j, new_A[i][j])    # Write to File\n",
    "workbook.close()\n",
    "\n",
    "\n",
    "array = np.array(new_A, dtype=np.uint8)       # Convert the pixels into an array using numpy\n",
    "new_image = Image.fromarray(array)            # Use PIL to create an image from the new array of pixels\n",
    "new_image.save('new.png')                     # Save New Image\n",
    "#new_image.show()\n",
    "\n",
    "\n",
    "max_cnt = 0\n",
    "target_row = 0\n",
    "similar = 0\n",
    "for i in range(len(A)):\n",
    "    count = 0         \n",
    "    for j in range(len(A[i])):\n",
    "        if (new_A[i][j] == 0):\n",
    "            count += 1                        # Make Temporary Count\n",
    "    if (count > max_cnt):\n",
    "        max_cnt = count\n",
    "        target_row = i                        # Select The \"Matra\" Row\n",
    "    if (count == max_cnt or count == max_cnt - 3 or count == max_cnt + 3):\n",
    "        if (i in range(target_row - 4, target_row + 4)):\n",
    "            similar += 1\n",
    "#print (target_row, take)\n",
    "\n",
    "\n",
    "for i in range(len(A[i])):\n",
    "    count = 0\n",
    "    for j in range(len(A)):\n",
    "        if (new_A[j][i] == 0):\n",
    "            count += 1\n",
    "    if (count <= (similar)):\n",
    "        for l in range(target_row - similar, target_row + 4):\n",
    "            if (new_A[l][i] == 0):\n",
    "                new_A[l][i] = 255\n",
    "                \n",
    "#Upper Zone\n",
    "                \n",
    "for i in range ((target_row - similar - 2), (target_row - similar + 2)):      \n",
    "    for j in range(len(A[i])):\n",
    "        if (new_A[i][j] == 0):\n",
    "            new_A[i][j] = 255\n",
    "\n",
    "array = np.array(new_A, dtype=np.uint8)       # Convert the pixels into an array using numpy\n",
    "new_image = Image.fromarray(array)            # Use PIL to create an image from the new array of pixels\n",
    "new_image.save('new1.png')                     # Save New Image\n",
    "            \n",
    "#Lowest Level\n",
    "\n",
    "lower = 5000\n",
    "\n",
    "imgTrainingNumbers = cv2.imread('new1.png')            # read in training numbers image\n",
    "allContoursWithData = []                # declare empty lists,\n",
    "validContoursWithData = []              # we will fill these shortly\n",
    "\n",
    "imgTestingNumbers = cv2.imread('new1.png')              # read in testing numbers image\n",
    "\n",
    "if imgTestingNumbers is None:                           # if image was not read successfully\n",
    "    print (\"error: image not read from file \\n\\n\")        # print error message to std out\n",
    "    os.system(\"pause\")                                  # pause so user can see error message\n",
    "    #return                                              # and exit function (which exits program)\n",
    "# end if\n",
    "\n",
    "imgGray = cv2.cvtColor(imgTestingNumbers, cv2.COLOR_BGR2GRAY)       # get grayscale image\n",
    "imgBlurred = cv2.GaussianBlur(imgGray, (5,5), 0)                    # blur\n",
    "\n",
    "                                                    # filter image from grayscale to black and white\n",
    "imgThresh = cv2.adaptiveThreshold(imgBlurred,                           # input image\n",
    "                                  255,                                  # make pixels that pass the threshold full white\n",
    "                                  cv2.ADAPTIVE_THRESH_GAUSSIAN_C,       # use gaussian rather than mean, seems to give better results\n",
    "                                  cv2.THRESH_BINARY_INV,                # invert so foreground will be white, background will be black\n",
    "                                  11,                                   # size of a pixel neighborhood used to calculate threshold value\n",
    "                                  2)                                    # constant subtracted from the mean or weighted mean\n",
    "\n",
    "imgThreshCopy = imgThresh.copy()        # make a copy of the thresh image, this in necessary b/c findContours modifies the image\n",
    "\n",
    "npaContours, npaHierarchy = cv2.findContours(imgThreshCopy,             # input image, make sure to use a copy since the function will modify this image in the course of finding contours\n",
    "                                             cv2.RETR_EXTERNAL,         # retrieve the outermost contours only\n",
    "                                             cv2.CHAIN_APPROX_SIMPLE)   # compress horizontal, vertical, and diagonal segments and leave only their end points\n",
    "\n",
    "for npaContour in npaContours:                             # for each contour\n",
    "    contourWithData = ContourWithData()                                             # instantiate a contour with data object\n",
    "    contourWithData.npaContour = npaContour                                         # assign contour to contour with data\n",
    "    contourWithData.boundingRect = cv2.boundingRect(contourWithData.npaContour)     # get the bounding rect\n",
    "    contourWithData.calculateRectTopLeftPointAndWidthAndHeight()                    # get bounding rect info\n",
    "    contourWithData.fltArea = cv2.contourArea(contourWithData.npaContour)           # calculate the contour area\n",
    "    allContoursWithData.append(contourWithData)                                     # add contour with data object to list of all contours with data\n",
    "# end for\n",
    "\n",
    "for contourWithData in allContoursWithData:                 # for all contours\n",
    "    if contourWithData.checkIfContourIsValid():             # check if valid\n",
    "        validContoursWithData.append(contourWithData)       # if so, append to valid contour list\n",
    "    # end if\n",
    "# end for\n",
    "\n",
    "validContoursWithData.sort(key = operator.attrgetter(\"intRectX\"))         # sort contours from left to right\n",
    "\n",
    "for contourWithData in validContoursWithData:            # for each contour\n",
    "                                            # draw a green rect around the current char\n",
    "    cv2.rectangle(imgTestingNumbers,                                        # draw rectangle on original testing image\n",
    "                  (contourWithData.intRectX, contourWithData.intRectY),     # upper left corner\n",
    "                  (contourWithData.intRectX + contourWithData.intRectWidth, contourWithData.intRectY + contourWithData.intRectHeight),      # lower right corner\n",
    "                  (0, 255, 0),              # green\n",
    "                  2)                        # thickness\n",
    "\n",
    "    imgROI = imgThresh[contourWithData.intRectY : contourWithData.intRectY + contourWithData.intRectHeight,     # crop char out of threshold image\n",
    "                       contourWithData.intRectX : contourWithData.intRectX + contourWithData.intRectWidth]\n",
    "    \n",
    "    if ((contourWithData.intRectY >= target_row - similar) and \n",
    "        (contourWithData.intRectY + contourWithData.intRectHeight < lower) and \n",
    "        (contourWithData.intRectHeight > similar * 2)):\n",
    "        lower = contourWithData.intRectY + contourWithData.intRectHeight\n",
    "        #print (lower)\n",
    "        #print (contourWithData.intRectHeight)\n",
    "    \n",
    "    #cv2.imshow(\"imgTestingNumbers1\", imgTestingNumbers)\n",
    "    #cv2.imshow(\"imgROI\", imgROI)\n",
    "    #plt.imsave('test.png', imgROI)\n",
    "    \n",
    "\n",
    "    imgROIResized = cv2.resize(imgROI, (RESIZED_IMAGE_WIDTH, RESIZED_IMAGE_HEIGHT))             # resize image, this will be more consistent for recognition and storage\n",
    "\n",
    "    npaROIResized = imgROIResized.reshape((1, RESIZED_IMAGE_WIDTH * RESIZED_IMAGE_HEIGHT))      # flatten image into 1d numpy array\n",
    "\n",
    "    npaROIResized = np.float32(npaROIResized)       # convert from 1d numpy array of ints to 1d numpy array of floats\n",
    "\n",
    "    intChar = cv2.waitKey(0)                     # get key press\n",
    "# end for\n",
    "#print (\"\\n\" + strFinalString + \"\\n\")                  # show the full string\n",
    "\n",
    "#cv2.imshow(\"imgTestingNumbers1\", imgTestingNumbers)      # show input image with green boxes drawn around found digits\n",
    "cv2.waitKey(0)                                          # wait for user key press\n",
    "\n",
    "cv2.destroyAllWindows()             # remove windows from memory\n",
    "\n",
    "#Lower Zone\n",
    "\n",
    "for i in range ((lower), (lower + similar)):      \n",
    "    for j in range(len(A[i])):\n",
    "        if (new_A[i][j] == 0):\n",
    "            new_A[i][j] = 255\n",
    "            \n",
    "array = np.array(new_A, dtype=np.uint8)       # Convert the pixels into an array using numpy\n",
    "new_image = Image.fromarray(array)            # Use PIL to create an image from the new array of pixels\n",
    "new_image.save('new2.png')                     # Save New Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import array as arr\n",
    "\n",
    "take = arr.array ('u', ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j'])\n",
    "take1 = 0\n",
    "take2 = 0\n",
    "take3 = 0\n",
    "take4 = 0\n",
    "take5 = 0\n",
    "take6 = 0\n",
    "take7 = 0\n",
    "take8 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def read_image(file_path):\n",
    "   #print(\"[INFO] loading and preprocessing image…\") \n",
    "   image = load_img(file_path, target_size=(224, 224)) \n",
    "   image = img_to_array(image) \n",
    "   image = np.expand_dims(image, axis=0)\n",
    "   image /= 255. \n",
    "   return image\n",
    "\n",
    "imgTrainingNumbers = cv2.imread(\"new1.png\")            # read in training numbers image\n",
    "allContoursWithData = []                # declare empty lists,\n",
    "validContoursWithData = []              # we will fill these shortly\n",
    "\n",
    "imgTestingNumbers = cv2.imread(\"new1.png\")              # read in testing numbers image\n",
    "\n",
    "if imgTestingNumbers is None:                           # if image was not read successfully\n",
    "    print (\"error: image not read from file \\n\\n\")        # print error message to std out\n",
    "    os.system(\"pause\")                                  # pause so user can see error message\n",
    "    #return                                              # and exit function (which exits program)\n",
    "# end if\n",
    "\n",
    "imgGray = cv2.cvtColor(imgTestingNumbers, cv2.COLOR_BGR2GRAY)       # get grayscale image\n",
    "imgBlurred = cv2.GaussianBlur(imgGray, (5,5), 0)                    # blur\n",
    "\n",
    "                                                    # filter image from grayscale to black and white\n",
    "imgThresh = cv2.adaptiveThreshold(imgBlurred,                           # input image\n",
    "                                  255,                                  # make pixels that pass the threshold full white\n",
    "                                  cv2.ADAPTIVE_THRESH_GAUSSIAN_C,       # use gaussian rather than mean, seems to give better results\n",
    "                                  cv2.THRESH_BINARY_INV,                # invert so foreground will be white, background will be black\n",
    "                                  11,                                   # size of a pixel neighborhood used to calculate threshold value\n",
    "                                  2)                                    # constant subtracted from the mean or weighted mean\n",
    "\n",
    "imgThreshCopy = imgThresh.copy()        # make a copy of the thresh image, this in necessary b/c findContours modifies the image\n",
    "\n",
    "npaContours, npaHierarchy = cv2.findContours(imgThreshCopy,             # input image, make sure to use a copy since the function will modify this image in the course of finding contours\n",
    "                                             cv2.RETR_EXTERNAL,         # retrieve the outermost contours only\n",
    "                                             cv2.CHAIN_APPROX_SIMPLE)   # compress horizontal, vertical, and diagonal segments and leave only their end points\n",
    "\n",
    "for npaContour in npaContours:                             # for each contour\n",
    "    contourWithData = ContourWithData()                                             # instantiate a contour with data object\n",
    "    contourWithData.npaContour = npaContour                                         # assign contour to contour with data\n",
    "    contourWithData.boundingRect = cv2.boundingRect(contourWithData.npaContour)     # get the bounding rect\n",
    "    contourWithData.calculateRectTopLeftPointAndWidthAndHeight()                    # get bounding rect info\n",
    "    contourWithData.fltArea = cv2.contourArea(contourWithData.npaContour)           # calculate the contour area\n",
    "    allContoursWithData.append(contourWithData)                                     # add contour with data object to list of all contours with data\n",
    "# end for\n",
    "\n",
    "for contourWithData in allContoursWithData:                 # for all contours\n",
    "    if contourWithData.checkIfContourIsValid():             # check if valid\n",
    "        validContoursWithData.append(contourWithData)       # if so, append to valid contour list\n",
    "    # end if\n",
    "# end for\n",
    "\n",
    "validContoursWithData.sort(key = operator.attrgetter(\"intRectX\"))         # sort contours from left to right\n",
    "\n",
    "#strFinalString = \"\"         # declare final string, this will have the final number sequence by the end of the program\n",
    "\n",
    "flag = flag1 = 0\n",
    "cnt = 1\n",
    "\n",
    "for contourWithData in validContoursWithData:            # for each contour\n",
    "                                            # draw a green rect around the current char\n",
    "    cv2.rectangle(imgTestingNumbers,                                        # draw rectangle on original testing image\n",
    "                  (contourWithData.intRectX, contourWithData.intRectY),     # upper left corner\n",
    "                  (contourWithData.intRectX + contourWithData.intRectWidth, contourWithData.intRectY + contourWithData.intRectHeight),      # lower right corner\n",
    "                  (0, 255, 0),              # green\n",
    "                  2)                        # thickness\n",
    "\n",
    "    imgROI = imgThresh[contourWithData.intRectY : contourWithData.intRectY + contourWithData.intRectHeight,     # crop char out of threshold image\n",
    "                       contourWithData.intRectX : contourWithData.intRectX + contourWithData.intRectWidth]\n",
    "    \n",
    "    if (contourWithData.intRectY >= (target_row - similar)):\n",
    "        take1 = contourWithData.intRectX\n",
    "        take2 = contourWithData.intRectX + contourWithData.intRectWidth\n",
    "        take3 = contourWithData.intRectY\n",
    "        take4 = contourWithData.intRectY + contourWithData.intRectHeight\n",
    "        \n",
    "    else:\n",
    "        take5 = contourWithData.intRectX\n",
    "        take6 = contourWithData.intRectX + contourWithData.intRectWidth\n",
    "        take7 = contourWithData.intRectY\n",
    "        take8 = contourWithData.intRectY + contourWithData.intRectHeight\n",
    "    \n",
    "    #cv2.imshow(\"imgTestingNumbers1\", imgTestingNumbers)\n",
    "    #cv2.imshow(\"imgROI\", imgROI)\n",
    "    plt.imsave('test.png', imgROI)\n",
    "    \n",
    "    \n",
    "    def test_single_image(path):\n",
    "      animals = ['অ', 'আ', 'ই', 'ঈ', 'উ', 'ঊ', 'ঋ', 'এ', 'ঐ', 'ও', 'ঔ', 'ক', 'খ', 'গ', 'ঘ', 'ঙ', 'চ', 'ছ', 'জ', \n",
    "            'ঝ', 'ঞ', 'ট', 'ঠ', 'ড', 'ঢ', 'ণ', 'ত', 'থ', 'দ', 'ধ', 'ন', 'প', 'ফ', 'ব', 'ভ', 'ম', 'য', 'র', 'ল', \n",
    "            'শ', 'ষ', 'স', 'হ', 'ড়', 'ঢ়', 'য়', 'া', 'ে', 'ু', 'ূ', 'ৃ', '০', '১', '২', '৩', '৪', '৫', '৬', '৭',\n",
    "             '৮','৯']\n",
    "      images = read_image(path)\n",
    "      time.sleep(.5)\n",
    "    \n",
    "    \n",
    "      bt_prediction = vgg16.predict(images) \n",
    "      preds = model.predict_proba(bt_prediction)\n",
    "      per = 0\n",
    "      for idx, animal, x in zip(range(0,61), animals , preds[0]):\n",
    "       if (round (x*100, 2) > per):\n",
    "        per = round (x*100, 2)\n",
    "        container = animal\n",
    "    \n",
    "       #print(\"ID: {}, Label: {} {}%\".format(idx, animal, round(x*100,2) ))\n",
    "            \n",
    "    \n",
    "      print('Final Decision:')\n",
    "      time.sleep(.5)\n",
    "    \n",
    "    \n",
    "      for x in range(3):\n",
    "       #print('.'*(x+1))\n",
    "       time.sleep(.2)\n",
    "      class_predicted = model.predict_classes(bt_prediction)\n",
    "      class_dictionary = generator_top.class_indices \n",
    "      inv_map = {v: k for k, v in class_dictionary.items()}\n",
    "    \n",
    "      if (container == 'ু'):\n",
    "        container = 'ড়'\n",
    "      elif (container == 'ূ'):\n",
    "        container = 'ঢ়'\n",
    "      elif (container == 'ৃ'):\n",
    "        container = 'য়'\n",
    "      elif (container == 'ড়'):\n",
    "        container = 'া'\n",
    "      elif (container == 'ঢ়'):\n",
    "        container = 'ু'\n",
    "      elif (container == 'য়'):\n",
    "        container = 'ূ'\n",
    "      elif (container == 'া'):\n",
    "        container = 'ৃ' \n",
    "    \n",
    "      global flag, flag1, take1, take2, take3, take4, take5, take6, take7, take8, cnt\n",
    "      \n",
    "      print(\"Character: {}, Label: {}, Accuracy: {}%\".format(class_predicted[0],  container, per))\n",
    "        \n",
    "      if (take3 >= (target_row - (similar * 2))):\n",
    "          if ((take2 - take1 <= (similar * 2)) and ((take4 - take3) <= (similar * 2))):\n",
    "                if (take[cnt - 1] == 'ড'):\n",
    "                    container = 'ড়'\n",
    "                    take[cnt - 1] = container\n",
    "                    print (\"ACCEPTED - \", container)\n",
    "                    print (\"logic - 17\")\n",
    "                    \n",
    "                elif (take[cnt - 1] == 'ঢ'):\n",
    "                    container = 'ঢ়'\n",
    "                    take[cnt - 1] = container\n",
    "                    print (\"ACCEPTED - \", container)\n",
    "                    print (\"logic - 18\")\n",
    "                    \n",
    "                elif (take[cnt - 1] == 'ব'):\n",
    "                    container = 'র'\n",
    "                    take[cnt - 1] = container\n",
    "                    print (\"ACCEPTED - \", container)\n",
    "                    print (\"logic - 19\")\n",
    "                    \n",
    "                elif (take[cnt - 1] == 'য'):\n",
    "                    container = 'য়'\n",
    "                    take[cnt - 1] = container\n",
    "                    print (\"ACCEPTED - \", container)\n",
    "                    print (\"logic - 20\")\n",
    "                \n",
    "          elif (per >= 25): \n",
    "            if (flag == 1):\n",
    "                if (container == 'া'):\n",
    "                    if (take6 > (take2 + 7)):\n",
    "                        container = 'ি'\n",
    "                    \n",
    "                    elif (take1 > (take5 + 7) and take[cnt - 1] != 'ধ'):\n",
    "                        container = 'ী'\n",
    "                        \n",
    "                    take[cnt] = container\n",
    "                    print (\"ACCEPTED - \", container)\n",
    "                    print (\"logic - 14\")\n",
    "                    cnt += 1\n",
    "                        \n",
    "                    flag = take5 = take6 = take7 = take8 = 0\n",
    "                    \n",
    "                elif (container == 'হ'):\n",
    "                    container = 'ই'\n",
    "                    take[cnt] = container\n",
    "                    print (\"ACCEPTED - \", container)\n",
    "                    print (\"logic - 5\")\n",
    "                    cnt += 1\n",
    "                    flag = 0\n",
    "                    \n",
    "                elif (container == 'ড'):\n",
    "                    container = 'উ'\n",
    "                    take[cnt] = container\n",
    "                    print (\"ACCEPTED - \", container)\n",
    "                    print (\"logic - 7\")\n",
    "                    cnt += 1\n",
    "                    flag = 0\n",
    "                    \n",
    "                elif (container == 'ঢ'):\n",
    "                    container = 'ট'\n",
    "                    take[cnt] = container\n",
    "                    print (\"ACCEPTED - \", container)\n",
    "                    print (\"logic - 8\")\n",
    "                    cnt += 1\n",
    "                    flag = 0\n",
    "                    \n",
    "                elif (container == 'ে'):\n",
    "                    container = 'ৈ'\n",
    "                    take[cnt] = container\n",
    "                    print (\"ACCEPTED - \", container)\n",
    "                    print (\"logic - 9\")\n",
    "                    cnt += 1\n",
    "                    flag = 0\n",
    "                    \n",
    "                elif (take[cnt - 1] == 'ি' and flag1 == 1):\n",
    "                    take[cnt] = (container)\n",
    "                    take[cnt - 1], take[cnt] = take[cnt], take[cnt - 1]\n",
    "                    print (\"ACCEPTED - \", container)\n",
    "                    print (\"logic - 21\")\n",
    "                    cnt += 1\n",
    "                    flag1 = 0\n",
    "                    \n",
    "                else:\n",
    "                    take[cnt] = (container)\n",
    "                    print (\"ACCEPTED - \", container)\n",
    "                    print (\"logic - 13\")\n",
    "                    cnt += 1\n",
    "                \n",
    "            elif (container == 'া'):\n",
    "                        \n",
    "                if ((take4 - take3) > (similar * 2)):\n",
    "                    \n",
    "                    if (take[cnt - 1] == 'ি' and flag1 == 1):\n",
    "                        take[cnt] = (container)\n",
    "                        take[cnt - 1], take[cnt] = take[cnt], take[cnt - 1]\n",
    "                        print (\"ACCEPTED - ি\")\n",
    "                        print (\"logic - 3\")\n",
    "                        cnt += 1\n",
    "                        flag1 = 0\n",
    "                        \n",
    "                    elif (take[cnt - 1] == 'ৈ'):\n",
    "                        container = 'ৌ'\n",
    "                        take[cnt - 1] = container\n",
    "                        print (\"ACCEPTED - \", container)\n",
    "                        print (\"logic - 15\")\n",
    "                        \n",
    "                    else:\n",
    "                        take[cnt] = container\n",
    "                        print (\"ACCEPTED - \", container)\n",
    "                        print (\"logic - 16\")\n",
    "                        cnt += 1\n",
    "                    \n",
    "                take1 = take2 = take3 = take4 = 0\n",
    "            \n",
    "            else:\n",
    "                take[cnt] = container\n",
    "                print (\"ACCEPTED - \", container)\n",
    "                print (\"logic - 1\")\n",
    "                \n",
    "                if (flag1 == 1 and (take[cnt - 1] == 'ি' or take[cnt - 1] == 'ে' or take[cnt - 1] == 'ৈ')):\n",
    "                    take[cnt - 1], take[cnt] = take[cnt], take[cnt - 1]\n",
    "                    flag1 = 0\n",
    "                    \n",
    "                elif (container == 'ে'):\n",
    "                    flag1 = 1\n",
    "                \n",
    "                cnt += 1\n",
    "                \n",
    "                take1 = take2 = take3 = take4 = 0\n",
    "                \n",
    "          else:\n",
    "            take1 = take2 = take3 = take4 = 0\n",
    "            \n",
    "      elif (take8 <= target_row):\n",
    "        if (take[cnt - 1] == 'া'):\n",
    "            container = 'ি'\n",
    "            take[cnt - 1] = container\n",
    "            print (\"ACCEPTED - \", container)\n",
    "            print (\"logic - 4\")\n",
    "            flag1 = 0\n",
    "            \n",
    "        if (take[cnt - 1] == 'হ'):\n",
    "            container = 'ই'\n",
    "            take[cnt - 1] = container\n",
    "            print (\"ACCEPTED - \", container)\n",
    "            print (\"logic - 6\")\n",
    "            flag1 = 1\n",
    "            \n",
    "        if (take[cnt - 1] == 'ড'):\n",
    "            container = 'উ'\n",
    "            take[cnt - 1] = container\n",
    "            print (\"ACCEPTED - \", container)\n",
    "            print (\"logic - 10\")\n",
    "            flag1 = 1\n",
    "            \n",
    "        if (take[cnt - 1] == 'ঢ'):\n",
    "            container = 'ট'\n",
    "            take[cnt - 1] = container\n",
    "            print (\"ACCEPTED - \", container)\n",
    "            print (\"logic - 11\")\n",
    "            flag1 = 1\n",
    "            \n",
    "        if (take[cnt - 1] == 'ে'):\n",
    "            container = 'ৈ'\n",
    "            take[cnt - 1] = container\n",
    "            print (\"ACCEPTED - \", container)\n",
    "            print (\"logic - 12\")\n",
    "            flag1 = 1\n",
    "        \n",
    "        else:    \n",
    "            flag = 1\n",
    "            flag1 = 1\n",
    "    \n",
    "    path = (r'C:\\Users\\th4pa\\Bangla\\test.png')\n",
    "    test_single_image(path)\n",
    "    \n",
    "\n",
    "    imgROIResized = cv2.resize(imgROI, (RESIZED_IMAGE_WIDTH, RESIZED_IMAGE_HEIGHT))             # resize image, this will be more consistent for recognition and storage\n",
    "\n",
    "    npaROIResized = imgROIResized.reshape((1, RESIZED_IMAGE_WIDTH * RESIZED_IMAGE_HEIGHT))      # flatten image into 1d numpy array\n",
    "\n",
    "    npaROIResized = np.float32(npaROIResized)       # convert from 1d numpy array of ints to 1d numpy array of floats\n",
    "\n",
    "    #intChar = cv2.waitKey(0)                     # get key press\n",
    "# end for\n",
    "\n",
    "#print (\"\\n\" + strFinalString + \"\\n\")                  # show the full string\n",
    "\n",
    "#cv2.imshow(\"imgTestingNumbers1\", imgTestingNumbers)      # show input image with green boxes drawn around found digits\n",
    "cv2.waitKey(0)                                          # wait for user key press\n",
    "\n",
    "cv2.destroyAllWindows()             # remove windows from memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "word = \"\"\n",
    "for temp in range (1, cnt):\n",
    "    word = word + take[temp]\n",
    "    \n",
    "print (word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
